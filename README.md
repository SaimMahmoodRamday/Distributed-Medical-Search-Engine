# ğŸ§  Distributed Medical Search Engine

This project is an AI-powered distributed search engine designed to help clinicians and researchers efficiently explore large-scale medical literature. It retrieves and summarizes/explains articles on generic level for non-professionals using LLM , streamlining the information overload problem in healthcare research. As it follows distributed architecture it is very time efficient.

---

## ğŸ“Œ Features

- ğŸ” Fast and intelligent medical search engine with various custom filters
- ğŸ§  Real-time abstractive summarization/generic explanation using Gemini LLM
- ğŸ—ƒï¸ Distributed architecture with separate frontend and backend
- âš™ï¸ Fault tolerance, replication, and sharding using Solr
- ğŸ“‰ Incorrect Query Handling , Retrieves the most relevant results

---

## ğŸ—ï¸ Distributed System Design

This project is built as a **distributed system** to ensure scalability, high availability, and fault tolerance:

- ğŸ”„ **Sharding**: Medical records are split across multiple Solr shards, enabling parallel indexing and distributed query processing.
- ğŸ“¦ **Replication**: Each shard is replicated on multiple nodes to ensure redundancy and continued availability during node failures.
- âš–ï¸ **Leader Election & Failover**: Apache ZooKeeper monitors node health and handles automatic failover and leader election.
- ğŸ³ **Containerized Infrastructure**: All Solr nodes and ZooKeeper instances are deployed in Docker containers for portability and consistent environments.
- ğŸ“Š **Performance Testing**: Apache JMeter simulates concurrent search and indexing workloads to evaluate system throughput and response time.


---

## ğŸš€ Project Setup Instructions

### ğŸ”§ Prerequisites

- Node.js (v18+)
- Python 3
- Docker & Docker Compose
- Google Gemini API Key

---

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/medical-search-engine.git
cd medical-search-engine
```

---

### 2. Frontend Setup

```bash
cd front
npm install
```

---

### 3. Backend Setup

```bash
cd ../back
npm install
npm install @google/generative-ai
```

> Create an `.env` file in the `back` folder:

```
GEMINI_API=your_api_key_here
```

---

### 4. Prepare the Medical Data

- Download your medical corpus XML files and place them in a folder named `raw_data/` in the project root.
- Convert them to JSON using the provided script:

```bash
python XML_to_JSON.py
```

> The JSON files will be saved into the `data/` directory.

---

### 5. Start Solr Cluster using Docker

```bash
docker-compose up -d
```

> This launches multiple Solr nodes and a ZooKeeper ensemble for orchestration.

---

### 6. Create Solr Collection with Shards and Replicas

```bash
docker exec -it medicalsearchengine-solr1-1 solr create_collection -c pubmed -d _default -shards 2 -replicationFactor 2 -p 8983
```

---

### 7. Index JSON Data into Solr

**Windows Command Prompt:**

```cmd
for %f in (data\*.json) do curl http://localhost:8983/solr/pubmed/update?commit=true -H "Content-Type: application/json" --data-binary @%f
```

**Linux/macOS Bash:**

```bash
for f in data/*.json; do
  curl http://localhost:8983/solr/pubmed/update?commit=true -H "Content-Type: application/json" --data-binary @"$f"
done
```

---

## ğŸ§ª Run the Project

Note: Solr should be running in the background in Docker.

### âœ… Start Frontend

```bash
cd front
npm start
```

### âœ… Start Backend

```bash
cd ../back
node index.js
```

---

## ğŸ“ˆ Performance Metrics

| Metric                 | Value               |
|------------------------|---------------------|
| Total Requests Sent    | 1000                |
| âœ… Successful Requests |  770                |
| âŒ Failed Requests     | 230                 |
| ğŸ•’ Avg. Response Time  | 13 ms               |
| âš¡ Throughput           | 10.0 requests/sec   |

---

## ğŸ–¼ï¸ UI Screenshots

### ğŸ” Interface

![Interface](./assets/searchenginegit.jpg)

---

## ğŸ’¡ Future Improvements

- Integrate relevance ranking
- Automation for data corpus
- Pure Semantic Search intergration using AI Models

---

## ğŸ“œ License

This project is licensed under the [MIT License](LICENSE).
